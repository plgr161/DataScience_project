{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brown-satin",
   "metadata": {},
   "source": [
    "# Data Challenge\n",
    "\n",
    "This notebook details the construction of the anaylisis for the project.\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "configured-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import make_scorer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-quality",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "- `X_train` and `X_test` both have $35$ columns that represent the same explanatory variables but over different time periods. \n",
    "\n",
    "- `X_train` and `Y_train` share the same column `ID` - each row corresponds to a unique ID associated wwith a day and a country. \n",
    "\n",
    "- The target of this challenge `TARGET` in `Y_train` corresponds to the price change for daily futures contracts of 24H electricity baseload. \n",
    "\n",
    "- **You will notice some columns have missing values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunrise-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We download the data as pandas Data Frames.\n",
    "\n",
    "X = pd.read_csv('X_train.csv')\n",
    "Y = pd.read_csv('Y_train.csv')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n",
    "#(Random state = 42 is used to have replicable results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heard-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DAY_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DE_CONSUMPTION</th>\n",
       "      <th>FR_CONSUMPTION</th>\n",
       "      <th>DE_FR_EXCHANGE</th>\n",
       "      <th>FR_DE_EXCHANGE</th>\n",
       "      <th>DE_NET_EXPORT</th>\n",
       "      <th>FR_NET_EXPORT</th>\n",
       "      <th>DE_NET_IMPORT</th>\n",
       "      <th>...</th>\n",
       "      <th>FR_RESIDUAL_LOAD</th>\n",
       "      <th>DE_RAIN</th>\n",
       "      <th>FR_RAIN</th>\n",
       "      <th>DE_WIND</th>\n",
       "      <th>FR_WIND</th>\n",
       "      <th>DE_TEMP</th>\n",
       "      <th>FR_TEMP</th>\n",
       "      <th>GAS_RET</th>\n",
       "      <th>COAL_RET</th>\n",
       "      <th>CARBON_RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1779</td>\n",
       "      <td>97</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.028612</td>\n",
       "      <td>-0.805939</td>\n",
       "      <td>-1.130925</td>\n",
       "      <td>1.130925</td>\n",
       "      <td>-1.737154</td>\n",
       "      <td>1.303680</td>\n",
       "      <td>1.737154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746805</td>\n",
       "      <td>-1.065734</td>\n",
       "      <td>0.269952</td>\n",
       "      <td>0.179885</td>\n",
       "      <td>0.453358</td>\n",
       "      <td>-0.073011</td>\n",
       "      <td>-1.686025</td>\n",
       "      <td>1.288241</td>\n",
       "      <td>-0.033589</td>\n",
       "      <td>0.141656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1869</td>\n",
       "      <td>672</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.764817</td>\n",
       "      <td>-0.108776</td>\n",
       "      <td>0.584286</td>\n",
       "      <td>-0.584286</td>\n",
       "      <td>0.153608</td>\n",
       "      <td>0.612692</td>\n",
       "      <td>-0.153608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.631747</td>\n",
       "      <td>-0.632019</td>\n",
       "      <td>0.148246</td>\n",
       "      <td>0.506879</td>\n",
       "      <td>1.584285</td>\n",
       "      <td>0.212696</td>\n",
       "      <td>0.659325</td>\n",
       "      <td>-2.959449</td>\n",
       "      <td>0.093542</td>\n",
       "      <td>-2.713832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1857</td>\n",
       "      <td>1132</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.820839</td>\n",
       "      <td>-0.128189</td>\n",
       "      <td>0.417064</td>\n",
       "      <td>-0.417064</td>\n",
       "      <td>-0.360641</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>0.360641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116523</td>\n",
       "      <td>0.248154</td>\n",
       "      <td>-0.653387</td>\n",
       "      <td>0.506200</td>\n",
       "      <td>0.358748</td>\n",
       "      <td>-1.186698</td>\n",
       "      <td>-1.021822</td>\n",
       "      <td>-0.798838</td>\n",
       "      <td>0.102641</td>\n",
       "      <td>1.757913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>618</td>\n",
       "      <td>180</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>-0.693302</td>\n",
       "      <td>-0.577114</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>-0.467340</td>\n",
       "      <td>1.175802</td>\n",
       "      <td>0.467340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.619215</td>\n",
       "      <td>2.383630</td>\n",
       "      <td>0.798208</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>0.693684</td>\n",
       "      <td>1.100208</td>\n",
       "      <td>0.713570</td>\n",
       "      <td>0.338003</td>\n",
       "      <td>-1.207689</td>\n",
       "      <td>0.644785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1528</td>\n",
       "      <td>503</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.501270</td>\n",
       "      <td>-0.796449</td>\n",
       "      <td>-0.480015</td>\n",
       "      <td>0.480015</td>\n",
       "      <td>-0.792889</td>\n",
       "      <td>-0.723719</td>\n",
       "      <td>0.792889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885554</td>\n",
       "      <td>0.574685</td>\n",
       "      <td>-0.486974</td>\n",
       "      <td>-0.409457</td>\n",
       "      <td>-0.262854</td>\n",
       "      <td>-0.326737</td>\n",
       "      <td>-1.061768</td>\n",
       "      <td>-0.645343</td>\n",
       "      <td>0.464638</td>\n",
       "      <td>0.263928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  DE_FR_EXCHANGE  \\\n",
       "1009  1779      97      FR       -0.028612       -0.805939       -1.130925   \n",
       "324   1869     672      FR        0.764817       -0.108776        0.584286   \n",
       "1352  1857    1132      FR        0.820839       -0.128189        0.417064   \n",
       "1074   618     180      DE        0.031579       -0.693302       -0.577114   \n",
       "1247  1528     503      FR       -0.501270       -0.796449       -0.480015   \n",
       "\n",
       "      FR_DE_EXCHANGE  DE_NET_EXPORT  FR_NET_EXPORT  DE_NET_IMPORT  ...  \\\n",
       "1009        1.130925      -1.737154       1.303680       1.737154  ...   \n",
       "324        -0.584286       0.153608       0.612692      -0.153608  ...   \n",
       "1352       -0.417064      -0.360641      -0.005078       0.360641  ...   \n",
       "1074        0.577114      -0.467340       1.175802       0.467340  ...   \n",
       "1247        0.480015      -0.792889      -0.723719       0.792889  ...   \n",
       "\n",
       "      FR_RESIDUAL_LOAD   DE_RAIN   FR_RAIN   DE_WIND   FR_WIND   DE_TEMP  \\\n",
       "1009         -0.746805 -1.065734  0.269952  0.179885  0.453358 -0.073011   \n",
       "324          -0.631747 -0.632019  0.148246  0.506879  1.584285  0.212696   \n",
       "1352         -0.116523  0.248154 -0.653387  0.506200  0.358748 -1.186698   \n",
       "1074         -0.619215  2.383630  0.798208  0.071497  0.693684  1.100208   \n",
       "1247         -0.885554  0.574685 -0.486974 -0.409457 -0.262854 -0.326737   \n",
       "\n",
       "       FR_TEMP   GAS_RET  COAL_RET  CARBON_RET  \n",
       "1009 -1.686025  1.288241 -0.033589    0.141656  \n",
       "324   0.659325 -2.959449  0.093542   -2.713832  \n",
       "1352 -1.021822 -0.798838  0.102641    1.757913  \n",
       "1074  0.713570  0.338003 -1.207689    0.644785  \n",
       "1247 -1.061768 -0.645343  0.464638    0.263928  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "durable-indicator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1779</td>\n",
       "      <td>-0.011401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1869</td>\n",
       "      <td>-0.047611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1857</td>\n",
       "      <td>0.376436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>618</td>\n",
       "      <td>0.311772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1528</td>\n",
       "      <td>-0.046973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    TARGET\n",
       "1009  1779 -0.011401\n",
       "324   1869 -0.047611\n",
       "1352  1857  0.376436\n",
       "1074   618  0.311772\n",
       "1247  1528 -0.046973"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-clock",
   "metadata": {},
   "source": [
    "## Model and train score\n",
    "\n",
    "The simplest model for this challenge consists in a simple linear regression, after a light cleaning of the data: The missing (NaN) values are simply filled with 0's and the `COUNTRY` column is dropped - namely we used the same model for France and Germany. \n",
    "\n",
    "In this project, our goal is to compare the efficiency of different challenger models compared to a champion model, the LinearRegression. We will not split the columns between FR and DE, instead we will keep a single dataset, to which we will apply the 4 models (champion and challenger)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-decrease",
   "metadata": {},
   "source": [
    "# Processing Data\n",
    "\n",
    "In this cell we reprocess the data in order to have a clean dataset. To measure the performance of our models, we use the spearman correlation between the Y predict and the Y_train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "meaning-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = X_train.drop(['ID','DAY_ID','COUNTRY','DE_FR_EXCHANGE'], axis=1).fillna(X_train.mean())\n",
    "Y_train_clean = Y_train['TARGET'].fillna(0)\n",
    "X_test_clean = X_test.drop(['ID','DAY_ID','COUNTRY','DE_FR_EXCHANGE'], axis=1).fillna(X_test.mean())\n",
    "Y_test_clean = Y_test['TARGET']\n",
    "\n",
    "def metric_train(output,Y_train):\n",
    "\n",
    "    return  100*spearmanr(output, Y_train).correlation\n",
    "\n",
    "# We create an object `scorer` to make Cross Validation. \n",
    "spearman_scorer = make_scorer(metric_train, greater_is_better=True)\n",
    "\n",
    "#WE also configurate the Cross Validation (KFold) (Random state is used to have replicable results)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-behavior",
   "metadata": {},
   "source": [
    "NB: Electricity price variations can be quite volatile and this is why we have chosen the Spearman rank correlation as a robust metric for our analysis, instead of the more standard Pearson correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-growth",
   "metadata": {},
   "source": [
    "# Training and Cross Validation of the champion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "committed-baghdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Scores: [13.96410934 13.12014392 22.01708565 27.97379943 21.79806445]\n",
      "Mean Spearman Correlation: 19.774640558565164\n",
      "Spearman correlation for the train set: 22.4%\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# We do a Cross Validation with the Cross Val Score function, and we use the spearman correlation as reference to train. \n",
    "scores = cross_val_score(\n",
    "    lr, \n",
    "    X_train_clean, \n",
    "    Y_train_clean, \n",
    "    cv=kf, \n",
    "    scoring=spearman_scorer\n",
    ")\n",
    "\n",
    "\n",
    "# Results\n",
    "print(\"Spearman Correlation Scores:\", scores)\n",
    "print(\"Mean Spearman Correlation:\", np.mean(scores))\n",
    "\n",
    "lr.fit(X_train_clean,Y_train_clean)\n",
    "output_train=lr.predict(X_test_clean)\n",
    "print('Spearman correlation for the test set: {:.1f}%'.format(metric_train(output_train, Y_test_clean) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-brick",
   "metadata": {},
   "source": [
    "This first approach show us that the relation between the datas and Y does not seem to be linear. \n",
    "The challenger models can be more flexible and permit hyperparametrization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-invalid",
   "metadata": {},
   "source": [
    "# Challenger models\n",
    "\n",
    "In this part we are going to use more relevant models, using the Machine Learning Map of Scikit Learn. \n",
    "We choose to deepen the analyse using RidgeRegression, the Lasso model and a RandomForest Regression. \n",
    "To be more efficient we use a GridSearch Cross Validation method which helps us to find the best parameters to train the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-department",
   "metadata": {},
   "source": [
    "# Ridge Regression : SVR (kernel = 'rbf') \n",
    "\n",
    "Kernel 'rbf' is equivalent to a Gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "powered-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'alpha': 5, 'gamma': 0.005, 'kernel': 'rbf'}\n",
      "Spearman Correlation Scores: [13.99357363 15.10835043 25.30459278 26.72217616 25.02509286]\n",
      "Mean Spearman Correlation: 21.230757171744127\n",
      "Spearman correlation for the train set: 20.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameters Grid: we did many tests to converge to these tree parameters for Gamma and Alpha. \n",
    "param_grid = {\n",
    "    'alpha': [1, 5, 10],\n",
    "    'gamma': [0.005,0.01,0.05],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(KernelRidge(), param_grid, cv=5, scoring=spearman_scorer)\n",
    "grid_search.fit(X_train_clean, Y_train_clean)\n",
    "\n",
    "print(\"Best parameters :\", grid_search.best_params_)\n",
    "\n",
    "# Utiliser les meilleurs paramètres\n",
    "best_krr = grid_search.best_estimator_\n",
    "y_pred_best = best_krr.predict(X_test_clean)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    best_krr, \n",
    "    X_train_clean, \n",
    "    Y_train_clean, \n",
    "    cv=kf, \n",
    "    scoring=spearman_scorer\n",
    ")\n",
    "\n",
    "\n",
    "# Results\n",
    "print(\"Spearman Correlation Scores:\", scores)\n",
    "print(\"Mean Spearman Correlation:\", np.mean(scores))\n",
    "\n",
    "print('Spearman correlation for the test set: {:.1f}%'.format(metric_train(y_pred_best, Y_test_clean) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-surrey",
   "metadata": {},
   "source": [
    "This solution provides us a result which seems to be worse, since the result on the training set is better than the result on the test set. Therefore, there could be a problem of overfitting, and we conclude that this challenger model is not improving our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-creature",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "\n",
    "This model is a type of linear regression that includes a regularization term. This regularization term helps to prevent overfitting by shrinking the coefficients of less important variables to zero, effectively performing variable selection. This makes the model simpler and more interpretable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "stone-international",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'alpha': 0.005}\n",
      "Spearman Correlation Scores: [15.47995442 15.64859071 23.88920776 27.83391595 24.13085946]\n",
      "Mean Spearman Correlation: 21.396505658812842\n",
      "Spearman correlation for the train set: 22.7%\n"
     ]
    }
   ],
   "source": [
    "T= np.arange(0.001,0.01,0.001)\n",
    "\n",
    "param_alpha=T.tolist()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': param_alpha\n",
    "}\n",
    "\n",
    "lasso = Lasso(max_iter=10000)\n",
    "\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring=spearman_scorer)\n",
    "grid_search.fit(X_train_clean, Y_train_clean)\n",
    "\n",
    "print(\"Best parameters :\", grid_search.best_params_)\n",
    "\n",
    "# We use the best parameters\n",
    "best_krr = grid_search.best_estimator_\n",
    "y_pred_best = best_krr.predict(X_test_clean)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    best_krr, \n",
    "    X_train_clean, \n",
    "    Y_train_clean, \n",
    "    cv=kf, \n",
    "    scoring=spearman_scorer\n",
    ")\n",
    "\n",
    "\n",
    "# Results\n",
    "print(\"Spearman Correlation Scores:\", scores)\n",
    "print(\"Mean Spearman Correlation:\", np.mean(scores))\n",
    "\n",
    "print('Spearman correlation for the test set: {:.1f}%'.format(metric_train(y_pred_best, Y_test_clean) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-lemon",
   "metadata": {},
   "source": [
    "In the first part of this analysis we identify the best parameter alpha for this regression. The results show us that the advantages of Lasso Regression are not improving our analysis. Lasso Regression tries to identify the most relevant variable, however in this case every variable seems to be relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-joyce",
   "metadata": {},
   "source": [
    "# Random Forest Regressor\n",
    "\n",
    "The Random Forest Regressor is a model that uses an group of decision trees to make predictions. Each tree in the forest is built from a random sample of the training data, and the predictions from all the trees are combined to produce a final prediction. This method helps to reduce the risk of overfitting and improves the robustness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "according-beijing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model1 = RandomForestRegressor()\n",
    "model1.fit(X_train_clean, Y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "charged-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'n_estimators': 95}\n",
      "Spearman Correlation Scores: [18.22269199  7.80857464 16.80779612 14.05548516 20.912333  ]\n",
      "Mean Spearman Correlation: 15.561376183994303\n",
      "Spearman correlation for the test set: 24.9%\n"
     ]
    }
   ],
   "source": [
    "T=np.arange(95,105,5)\n",
    "estimators_param=T.tolist()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': estimators_param\n",
    "}\n",
    "\n",
    "model1 = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(model1, param_grid, cv=5, scoring=spearman_scorer)\n",
    "grid_search.fit(X_train_clean, Y_train_clean)\n",
    "\n",
    "print(\"Best parameters :\", grid_search.best_params_)\n",
    "\n",
    "# We use the best parameters\n",
    "best_krr = grid_search.best_estimator_\n",
    "y_pred_best = best_krr.predict(X_test_clean)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    best_krr, \n",
    "    X_train_clean, \n",
    "    Y_train_clean, \n",
    "    cv=kf, \n",
    "    scoring=spearman_scorer\n",
    ")\n",
    "\n",
    "# Results\n",
    "print(\"Spearman Correlation Scores:\", scores)\n",
    "print(\"Mean Spearman Correlation:\", np.mean(scores))\n",
    "\n",
    "print('Spearman correlation for the test set: {:.1f}%'.format(metric_train(y_pred_best, Y_test_clean) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-charge",
   "metadata": {},
   "source": [
    "We can see that this method is the most efficient across our analysis. Results on the train sets are low, but we do not overfit and we have the highest, among the 4 models, Spearman correlation on the test set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
